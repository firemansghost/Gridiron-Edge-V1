name: Historical Odds Backfill

on:
  workflow_dispatch:
    inputs:
      season:
        description: 'Season year (e.g., 2024)'
        required: true
        default: '2024'
        type: string
      weeks:
        description: 'Week range (e.g., 2, 1-3, 2,3,5)'
        required: true
        default: '2'
        type: string
      markets:
        description: 'Markets to fetch (comma-separated)'
        required: false
        default: 'spreads,totals'
        type: string
      regions:
        description: 'Regions to fetch (comma-separated)'
        required: false
        default: 'us'
        type: string
      credits_limit:
        description: 'Maximum credits to use'
        required: false
        default: '1200'
        type: string
      dry_run:
        description: 'Dry run mode (no DB writes)'
        required: false
        default: false
        type: boolean
      historical_strict:
        description: 'Enable strict historical mode'
        required: false
        default: 'true'
        type: boolean
      max_events:
        description: 'Maximum events to process (for testing, leave empty for all)'
        required: false
        default: ''
        type: string
      enable_season_fallback:
        description: 'Enable season-only fallback for date mismatches (±8d)'
        required: false
        default: true
        type: boolean
      concurrency:
        description: 'Concurrency control (1-5)'
        required: false
        default: '1'
        type: choice
        options:
          - '1'
          - '2'
          - '3'
          - '4'
          - '5'

concurrency:
  group: backfill-odds-${{ github.ref }}-${{ inputs.season }}-${{ inputs.weeks }}
  cancel-in-progress: false

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Print Node version
        run: node -v

      - name: Install dependencies
        run: npm ci

      - name: Generate Prisma client
        run: npm run prisma:generate

      - name: Build jobs
        run: npm run build:jobs

      - name: Verify build output
        run: |
          echo "Checking if compiled files exist..."
          ls -la apps/jobs/dist/
          echo "Checking for ingest-minimal.js..."
          if [ -f "apps/jobs/dist/ingest-minimal.js" ]; then
            echo "✅ ingest-minimal.js exists"
            echo "File size: $(wc -c < apps/jobs/dist/ingest-minimal.js) bytes"
            echo "First 5 lines:"
            head -5 apps/jobs/dist/ingest-minimal.js
          else
            echo "❌ ingest-minimal.js not found!"
            echo "Available files in dist/:"
            ls -la apps/jobs/dist/
            exit 1
          fi

      - name: Setup environment
        run: |
          echo "ODDS_API_KEY=${{ secrets.ODDS_API_KEY }}" >> $GITHUB_ENV
          echo "DATABASE_URL=${{ secrets.DATABASE_URL }}" >> $GITHUB_ENV
          echo "HISTORICAL_STRICT=${{ inputs.historical_strict }}" >> $GITHUB_ENV
          echo "HISTORICAL_ALLOWED_SEASON=${{ inputs.season }}" >> $GITHUB_ENV
          echo "HISTORICAL_ALLOWED_WEEKS=${{ inputs.weeks }}" >> $GITHUB_ENV
          echo "CREDITS_LIMIT=${{ inputs.credits_limit }}" >> $GITHUB_ENV
          echo "ODDSAPI_ENABLE_SEASON_FALLBACK=${{ inputs.enable_season_fallback && 'true' || 'false' }}" >> $GITHUB_ENV

      - name: Test compiled file
        run: |
          echo "Testing compiled file with help command..."
          node apps/jobs/dist/ingest-minimal.js --help || echo "Help command failed, but continuing..."

      - name: Validate team aliases (duplicate keys check)
        run: |
          echo "Checking team_aliases.yml for duplicate keys..."
          node -e "
            const fs = require('fs');
            const yaml = require('js-yaml');
            const path = 'apps/jobs/config/team_aliases.yml';
            try {
              const content = fs.readFileSync(path, 'utf8');
              const lines = content.split('\\n');
              const keys = new Set();
              const dupes = [];
              lines.forEach((line, idx) => {
                const match = line.match(/^\\s*\"([^\"]+)\":\\s*/);
                if (match) {
                  const key = match[1];
                  if (keys.has(key)) {
                    dupes.push(\`Line \${idx+1}: \${key}\`);
                  }
                  keys.add(key);
                }
              });
              if (dupes.length > 0) {
                console.error('❌ FATAL: Duplicate keys found in team_aliases.yml:');
                dupes.forEach(d => console.error('  -', d));
                process.exit(1);
              }
              console.log('✅ No duplicate keys found');
              console.log(\`   Total unique keys: \${keys.size}\`);
            } catch (err) {
              console.error('❌ FATAL: Failed to validate aliases:', err.message);
              process.exit(1);
            }
          "

      - name: Validate FBS team index size
        run: |
          echo "Checking FBS team index will be adequately sized..."
          node -e "
            const { PrismaClient } = require('@prisma/client');
            const fs = require('fs');
            const prisma = new PrismaClient();
            (async () => {
              // Check teams table
              const teams = await prisma.team.findMany().catch(() => []);
              console.log(\`Teams table: \${teams.length} rows\`);
              
              // Check static fallback
              const staticPath = 'apps/jobs/config/fbs_slugs.json';
              const staticSlugs = fs.existsSync(staticPath) 
                ? JSON.parse(fs.readFileSync(staticPath, 'utf8'))
                : [];
              console.log(\`Static FBS slugs: \${staticSlugs.length} entries\`);
              
              // Sanity check: at least one source should have decent data
              const combined = teams.length + staticSlugs.length;
              if (combined < 100) {
                console.error(\`❌ FATAL: Combined team sources undersized (\${combined} < 100)\`);
                console.error('   This will cause index build to fail.');
                process.exit(1);
              }
              
              console.log(\`✅ Team sources look adequate (combined: \${combined})\`);
              process.exit(0);
            })().catch(err => {
              console.error('❌ FATAL: Failed to check team index:', err.message);
              process.exit(1);
            });
          "
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}

      - name: Validate aliases against denylist
        run: |
          echo "Checking team_aliases.yml for denylisted targets..."
          node -e "
            const fs = require('fs');
            const yaml = require('js-yaml');
            const aliasPath = 'apps/jobs/config/team_aliases.yml';
            const denylistPath = 'apps/jobs/config/denylist.ts';
            
            try {
              // Load denylist
              const denylistContent = fs.readFileSync(denylistPath, 'utf8');
              const denylistMatch = denylistContent.match(/DENYLIST_SLUGS = new Set\\(\\[([^\\]]+)\\]/);
              if (!denylistMatch) {
                console.error('❌ FATAL: Could not parse DENYLIST_SLUGS');
                process.exit(1);
              }
              const denylistSlugs = denylistMatch[1]
                .split(',')
                .map(s => s.trim().replace(/['\"]/g, ''))
                .filter(s => s && !s.startsWith('//'));
              
              // Extract FBS college exceptions from denylist.ts
              const exceptionsMatch = denylistContent.match(/fbsCollegeExceptions = new Set\\(\\[([^\\]]+)\\]/);
              const fbsExceptions = exceptionsMatch 
                ? exceptionsMatch[1]
                    .split(',')
                    .map(s => s.trim().replace(/['\"]/g, '').split('//')[0].trim()) // Remove inline comments
                    .filter(s => s && s.length > 0)
                : ['boston-college']; // Fallback default
              
              console.log(\`Denylist: \${denylistSlugs.length} slug(s)\`);
              console.log(\`FBS college exceptions: \${fbsExceptions.length} slug(s)\`);
              
              // Load aliases
              const aliasContent = fs.readFileSync(aliasPath, 'utf8');
              const config = yaml.load(aliasContent);
              const aliases = config.aliases || {};
              
              // Check for denylisted targets
              const violations = [];
              for (const [key, target] of Object.entries(aliases)) {
                if (denylistSlugs.includes(target)) {
                  violations.push(\`  - \"\${key}\" → \${target} (denylisted)\`);
                }
                // Check *-college pattern but exclude FBS exceptions
                if (target.endsWith('-college') && !fbsExceptions.includes(target)) {
                  violations.push(\`  - \"\${key}\" → \${target} (*-college pattern, not in FBS exceptions)\`);
                }
              }
              
              if (violations.length > 0) {
                console.error('❌ FATAL: Found alias targets that are denylisted or non-FBS:');
                violations.forEach(v => console.error(v));
                process.exit(1);
              }
              
              console.log('✅ No denylisted targets found in aliases');
              console.log(\`   Validated \${Object.keys(aliases).length} alias mappings\`);
            } catch (err) {
              console.error('❌ FATAL: Failed to validate aliases:', err.message);
              process.exit(1);
            }
          "

      - name: Echo DB host (safety)
        run: |
          echo "DB_URL host: $(node -e "try{const u=new URL(process.env.DATABASE_URL||'');console.log(u.host)}catch(e){console.log('NO_DB_URL')}")"

      - name: Echo Prisma target
        run: |
          node -e "try{const u=new URL(process.env.DATABASE_URL||'');console.log({protocol:u.protocol,host:u.host,db:u.pathname})}catch(e){console.log('NO_DB_URL')}"

      - name: Run historical backfill
        run: |
          echo "Running historical backfill with parameters:"
          echo "Season: ${{ inputs.season }}"
          echo "Weeks: ${{ inputs.weeks }}"
          echo "Markets: ${{ inputs.markets }}"
          echo "Regions: ${{ inputs.regions }}"
          echo "Credits limit: ${{ inputs.credits_limit }}"
          echo "Dry run: ${{ inputs.dry_run }}"
          echo "Historical strict: ${{ inputs.historical_strict }}"
          echo "Season fallback: ${{ inputs.enable_season_fallback }}"
          echo ""
          node apps/jobs/dist/ingest-minimal.js oddsapi \
            --season "${{ inputs.season }}" \
            --weeks "${{ inputs.weeks }}" \
            --markets "${{ inputs.markets }}" \
            --regions "${{ inputs.regions }}" \
            --credits-limit "${{ inputs.credits_limit }}" \
            --historical=${{ inputs.historical && 'true' || 'false' }} \
            --historical-strict=${{ inputs.historical_strict && 'true' || 'false' }} \
            --dry-run=${{ inputs.dry_run && 'true' || 'false' }} \
            ${{ inputs.max_events && format('--max-events {0}', inputs.max_events) || '' }}
        env:
          DEBUG: ingest:*,oddsapi:*,adapter:*
          NODE_OPTIONS: --trace-warnings

      - name: Post-run count for 2024 W2
        run: |
          node -e "const {PrismaClient}=require('@prisma/client');const p=new PrismaClient();(async()=>{const c=await p.marketLine.count({where:{season:2024,week:2}});console.log('Post-run market_lines count (2024,2):',c);process.exit(0)})().catch(e=>{console.error(e);process.exit(1)})"

      - name: Ensure artifacts exist
        run: |
          mkdir -p reports/historical
          touch reports/historical/map_2024_w2.jsonl
          touch reports/historical/errors_2024_w2.jsonl
          echo "Artifacts created:"
          ls -la reports/historical/

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: historical-reports-${{ inputs.season }}-w${{ inputs.weeks }}
          path: |
            reports/historical/
          retention-days: 30

      - name: Job summary
        if: always()
        run: |
          echo "## Historical Odds Backfill Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Season:** ${{ inputs.season }}" >> $GITHUB_STEP_SUMMARY
          echo "**Weeks:** ${{ inputs.weeks }}" >> $GITHUB_STEP_SUMMARY
          echo "**Markets:** ${{ inputs.markets }}" >> $GITHUB_STEP_SUMMARY
          echo "**Regions:** ${{ inputs.regions }}" >> $GITHUB_STEP_SUMMARY
          echo "**Credits Limit:** ${{ inputs.credits_limit }}" >> $GITHUB_STEP_SUMMARY
          echo "**Dry Run:** ${{ inputs.dry_run }}" >> $GITHUB_STEP_SUMMARY
          echo "**Historical Strict:** ${{ inputs.historical_strict }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Reports have been uploaded as artifacts." >> $GITHUB_STEP_SUMMARY